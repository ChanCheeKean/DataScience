{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"ExecuteTime":{"end_time":"2020-06-30T11:10:18.665569Z","start_time":"2020-06-30T11:10:18.424884Z"},"id":"VPDWZoy_sAwO","executionInfo":{"status":"ok","timestamp":1665385233843,"user_tz":-480,"elapsed":6,"user":{"displayName":"Kean Chan","userId":"05792587367281359063"}}},"outputs":[],"source":["import numpy as np\n","import cv2 "]},{"cell_type":"markdown","metadata":{"id":"xzIiSkpysAwT"},"source":["# 1) Optical Flow"]},{"cell_type":"markdown","metadata":{"id":"hOUaJ3QssAwV"},"source":["## 1.1 Lucas-Kanade Optical Flow\n","\n","Detect the motion of specific points or the aggregated motion of regions by modifying the winSize argument. This determines the integration window size. Small windows are more sensitive to noise and may miss larger motions. Large windows will “survive” an occlusion.\n","\n","The integration appears smoother with the larger window size.\n","\n","criteria has two here - the max number (10 above) of iterations and epsilon (0.03 above). More iterations means a more exhaustive search, and a smaller epsilon finishes earlier. These are primarily useful in exchanging speed vs accuracy, but mainly stay the same.\n","\n","When maxLevel is 0, it is the same algorithm without using pyramids (ie, calcOpticalFlowLK). Pyramids allow finding optical flow at various resolutions of the image."]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-06-30T11:11:03.976905Z","start_time":"2020-06-30T11:11:03.972901Z"},"id":"fxUP6pYAsAwX"},"outputs":[],"source":["# Parameters for ShiTomasi corner detection (good features to track paper)\n","# track 10 corners\n","corner_track_params = dict(\n","    maxCorners = 10,\n","    qualityLevel = 0.3,\n","    minDistance = 7,\n","    blockSize = 7\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-06-30T11:11:21.747970Z","start_time":"2020-06-30T11:11:21.743975Z"},"id":"4CnrsB7ysAwZ"},"outputs":[],"source":["# Parameters for lucas kanade optical flow\n","# small window more sensitve but might miss larger motion/moving fast\n","# high level lower resolution \n","# iterations = 10\n","lk_params = dict(\n","    winSize  = (200,200),\n","    maxLevel = 2,\n","    criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10,0.03)\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-06-30T11:12:28.477786Z","start_time":"2020-06-30T11:12:18.164114Z"},"id":"mn9wSzOqsAwa"},"outputs":[],"source":["# Capture the video\n","cap = cv2.VideoCapture(0)\n","\n","# Grab the very first frame of the stream\n","ret, prev_frame = cap.read()\n","\n","# Grab a grayscale image (We will refer to this as the previous frame)\n","prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n","\n","# Grabbing the corners\n","prevPts = cv2.goodFeaturesToTrack(prev_gray, mask = None, **corner_track_params)\n","\n","# Create a matching mask of the previous frame for drawing on later\n","mask = np.zeros_like(prev_frame)\n","\n","while True:\n","    # Grab current frame\n","    ret,frame = cap.read()\n","    \n","    # Grab gray scale\n","    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","    \n","    # Calculate the Optical Flow on the Gray Scale Frame\n","    nextPts, status, err = cv2.calcOpticalFlowPyrLK(prev_gray, frame_gray, prevPts, None, **lk_params)\n","    \n","    # Using the returned status array (the status output)\n","    # status output status vector (of unsigned chars); each element of the vector is set to 1 if\n","    # the flow for the corresponding features has been found, otherwise, it is set to 0.\n","    good_new = nextPts[status==1]\n","    good_prev = prevPts[status==1]\n","    \n","    # Use ravel to get points to draw lines and circles\n","    for i,(new,prev) in enumerate(zip(good_new,good_prev)):\n","        \n","        x_new,y_new = new.ravel()\n","        x_prev,y_prev = prev.ravel()\n","        \n","        # Lines will be drawn using the mask created from the first frame\n","        mask = cv2.line(mask, (x_new,y_new),(x_prev,y_prev), (0,255,0), 3)\n","        \n","        # Draw red circles at corner points\n","        frame = cv2.circle(frame,(x_new,y_new),8,(0,0,255),-1)\n","    \n","    # Display the image along with the mask we drew the line on.\n","    img = cv2.add(frame,mask)\n","    cv2.imshow('frame',img)\n","    \n","    k = cv2.waitKey(30) & 0xff\n","    if k == 27:\n","        break\n","   \n","    # Now update the previous frame and previous points\n","    prev_gray = frame_gray.copy()\n","    prevPts = good_new.reshape(-1,1,2)\n","    \n","cv2.destroyAllWindows()\n","cap.release()"]},{"cell_type":"markdown","metadata":{"id":"NLql0uZ7sAwc"},"source":["## 1.1 Dense Optical Flow in OpenCV\n","\n","calcOpticalFlowFarneback(prev, next, flow, pyr_scale, levels, winsize, iterations, poly_n, poly_sigma, flags) -> flow\n","\n","This function computes a dense optical flow using the Gunnar Farneback's algorithm.\n","\n","Here are the parameters for the function and what they represent:\n","\n","* prev first 8-bit single-channel input image.\n","* next second input image of the same size and the same type as prev.\n","* flow computed flow image that has the same size as prev and type CV_32FC2.\n","* pyr_scale parameter, specifying the image scale (\\<1) to build pyramids for each image\n","    * pyr_scale=0.5 means a classical pyramid, where each next layer is twice smaller than the previous one.\n","    \n","* levels number of pyramid layers including the initial image; levels=1 means that no extra layers are created and only the original images are used.\n","* winsize averaging window size\n","    * larger values increase the algorithm robustness to image\n","* noise and give more chances for fast motion detection, but yield more blurred motion field.\n","* iterations number of iterations the algorithm does at each pyramid level.\n","* poly_n size of the pixel neighborhood used to find polynomial expansion in each pixel\n","    * larger values mean that the image will be approximated with smoother surfaces, yielding more robust algorithm and more blurred motion field, typically poly_n =5 or 7.\n","* poly_sigma standard deviation of the Gaussian that is used to smooth derivatives used as a basis for the polynomial expansion; for poly_n=5, you can set poly_sigma=1.1, for poly_n=7, a good value would be poly_sigma=1.5.\n","   "]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-06-30T11:13:12.664558Z","start_time":"2020-06-30T11:13:04.642737Z"},"id":"LDRAdSIcsAwd"},"outputs":[],"source":["# Capture the frame\n","cap = cv2.VideoCapture(0)\n","ret, frame1 = cap.read()\n","\n","# Get gray scale image of first frame and make a mask in HSV color\n","prvsImg = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n","\n","hsv_mask = np.zeros_like(frame1)\n","hsv_mask[:,:,1] = 255\n","\n","while True:\n","    ret, frame2 = cap.read()\n","    nextImg = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n","    \n","    # Check out the markdown text above for a break down of these paramters, most of these are just suggested defaults\n","    flow = cv2.calcOpticalFlowFarneback(prvsImg,nextImg, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n","    \n","    \n","    # Color the channels based on the angle of travel\n","    # Pay close attention to your video, the path of the direction of flow will determine color!\n","    mag, ang = cv2.cartToPolar(flow[:,:,0], flow[:,:,1],angleInDegrees=True)\n","    hsv_mask[:,:,0] = ang/2\n","    hsv_mask[:,:,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n","    \n","    # Convert back to BGR to show with imshow from cv\n","    bgr = cv2.cvtColor(hsv_mask,cv2.COLOR_HSV2BGR)\n","    cv2.imshow('frame2',bgr)\n","    \n","    k = cv2.waitKey(30) & 0xff\n","    if k == 27:\n","        break\n","    \n","    # Set the Previous image as the next iamge for the loop\n","    prvsImg = nextImg\n","\n","    \n","cap.release()\n","cv2.destroyAllWindows()"]},{"cell_type":"markdown","metadata":{"id":"c69CUOvBsAwe"},"source":["# 2) Mean Shift Tracking"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-06-30T11:14:46.405013Z","start_time":"2020-06-30T11:14:32.677253Z"},"id":"9yqU4JvrsAwf"},"outputs":[],"source":["# Capture a video stream\n","cap = cv2.VideoCapture(0)\n","\n","# take first frame of the video\n","ret,frame = cap.read()\n","\n","# Set Up the Initial Tracking Window\n","\n","# We will first detect the face and set that as our starting box.\n","face_cascade = cv2.CascadeClassifier(\n","    'https://raw.githubusercontent.com/kipr/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml'\n",")\n","face_rects = face_cascade.detectMultiScale(frame) \n","\n","# Convert this list of a single array to a tuple of (x,y,w,h)\n","# only need one face!\n","(face_x,face_y,w,h) = tuple(face_rects[0]) \n","track_window = (face_x,face_y,w,h)\n","# set up the ROI for tracking\n","roi = frame[face_y:face_y+h, face_x:face_x+w]\n","\n","# Use the HSV Color Mapping\n","hsv_roi =  cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n","\n","# Find histogram to backproject the target on each frame for calculation of meanshit\n","roi_hist = cv2.calcHist([hsv_roi],[0],None,[180],[0,180])\n","\n","# Normalize the histogram array values given a min of 0 and max of 255\n","cv2.normalize(roi_hist,roi_hist,0,255,cv2.NORM_MINMAX)\n","\n","# Setup the termination criteria, either 10 iteration or move by at least 1 pt\n","term_crit = ( cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1 )\n","\n","while True:\n","    ret ,frame = cap.read()\n","    if ret == True:\n","        \n","        # Grab the Frame in HSV\n","        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n","        \n","        # Calculate the Back Projection based off the roi_hist created earlier\n","        dst = cv2.calcBackProject([hsv],[0],roi_hist,[0,180],1)\n","        \n","        # Apply meanshift to get the new coordinates of the rectangle\n","        ret, track_window = cv2.meanShift(dst, track_window, term_crit)\n","        \n","        # Draw the new rectangle on the image\n","        x,y,w,h = track_window\n","        img2 = cv2.rectangle(frame, (x,y), (x+w,y+h), (0,0,255),5)\n","        \n","        cv2.imshow('img2',img2)\n","        k = cv2.waitKey(1) & 0xff\n","        if k == 27:\n","            break\n","        \n","    else:\n","        break\n","        \n","cv2.destroyAllWindows()\n","cap.release()"]},{"cell_type":"markdown","metadata":{"id":"sRD-wI0ZsAwf"},"source":["# 3) CamShift Tracking"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-06-30T11:16:26.985013Z","start_time":"2020-06-30T11:16:16.036208Z"},"id":"6FQDYSVHsAwg"},"outputs":[],"source":["# Capture a video stream\n","cap = cv2.VideoCapture(0)\n","\n","# take first frame of the video\n","ret,frame = cap.read()\n","\n","\n","# Set Up the Initial Tracking Window\n","\n","\n","# We will first detect the face and set that as our starting box.\n","face_cascade = cv2.CascadeClassifier(\n","    'https://raw.githubusercontent.com/kipr/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml'\n",")\n","face_rects = face_cascade.detectMultiScale(frame) \n","\n","# Convert this list of a single array to a tuple of (x,y,w,h)\n","(face_x,face_y,w,h) = tuple(face_rects[0]) \n","track_window = (face_x,face_y,w,h)\n","# set up the ROI for tracking\n","roi = frame[face_y:face_y+h, face_x:face_x+w]\n","\n","\n","# Use the HSV Color Mapping\n","hsv_roi =  cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n","\n","# Find histogram to backproject the target on each frame for calculation of meanshit\n","roi_hist = cv2.calcHist([hsv_roi],[0],None,[180],[0,180])\n","\n","# Normalize the histogram array values given a min of 0 and max of 255\n","cv2.normalize(roi_hist,roi_hist,0,255,cv2.NORM_MINMAX)\n","\n","\n","# Setup the termination criteria, either 10 iteration or move by at least 1 pt\n","term_crit = ( cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1 )\n","\n","while True:\n","    ret ,frame = cap.read()\n","    if ret == True:\n","        \n","        # Grab the Frame in HSV\n","        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n","        \n","        # Calculate the Back Projection based off the roi_hist created earlier\n","        dst = cv2.calcBackProject([hsv],[0],roi_hist,[0,180],1)\n","        \n","        #########################################################\n","        #########################################################\n","        ########## CAM SHIFT ####################################\n","        ########################################################\n","        #######################################################\n","        \n","        # Apply Camshift to get the new coordinates of the rectangle\n","        ret, track_window = cv2.CamShift(dst, track_window, term_crit)\n","        \n","        # Draw it on image\n","        pts = cv2.boxPoints(ret)\n","        pts = np.int0(pts)\n","        img2 = cv2.polylines(frame,[pts],True, (0,0,255),5)\n","        cv2.imshow('img2',img2)\n","        \n","        ########################################################\n","        #######################################################\n","        ########################################################\n","        #######################################################\n","        \n","        k = cv2.waitKey(1) & 0xff\n","        if k == 27:\n","            break\n","        \n","    else:\n","        break\n","        \n","cv2.destroyAllWindows()\n","cap.release()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":true},"colab":{"provenance":[],"collapsed_sections":[],"toc_visible":true}},"nbformat":4,"nbformat_minor":0}