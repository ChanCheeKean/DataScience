{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"provenance":[],"toc_visible":true},"coursera":{"schema_names":["NLPC3-3A"]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"a388e0621cf7472a8286c9e8c4d30531":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e0f5db3629ff46e1bfbf663e5b814429","IPY_MODEL_0f90bc66b907499aaccf8443ddeb04bf","IPY_MODEL_17eb5eaa7dfb4b1d870700d6c9e68cb0"],"layout":"IPY_MODEL_a99c0a38a41e471c90e76beaa1fdf7f9"}},"e0f5db3629ff46e1bfbf663e5b814429":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e7b68a71b8604724803d2d1be961e9f6","placeholder":"​","style":"IPY_MODEL_8393e7d1d9ac4e70b81302616de6db95","value":"Downloading (…)okenizer_config.json: 100%"}},"0f90bc66b907499aaccf8443ddeb04bf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f9a472f636584b308574b46ffd2592ba","max":29,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f68b98c41b50428f8698ed7b9fc0c14a","value":29}},"17eb5eaa7dfb4b1d870700d6c9e68cb0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_78ee3e24cfbd40579e842d65794cf7d5","placeholder":"​","style":"IPY_MODEL_bd06bbfbb8a2491e86b8c3a335a5bead","value":" 29.0/29.0 [00:00&lt;00:00, 1.92kB/s]"}},"a99c0a38a41e471c90e76beaa1fdf7f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e7b68a71b8604724803d2d1be961e9f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8393e7d1d9ac4e70b81302616de6db95":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f9a472f636584b308574b46ffd2592ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f68b98c41b50428f8698ed7b9fc0c14a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"78ee3e24cfbd40579e842d65794cf7d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd06bbfbb8a2491e86b8c3a335a5bead":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bf139f023c1f41c188e9f80ccda80651":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2558eeab980b4052bccfdfdd075df31e","IPY_MODEL_00df77aa9bd342189f62e69a43d608ac","IPY_MODEL_8659d3eb43c74cb483f84b58da1a3a24"],"layout":"IPY_MODEL_4a4d219f8753498ba34622010acff94f"}},"2558eeab980b4052bccfdfdd075df31e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d37fa851391d4fb095e45abcf2ab475e","placeholder":"​","style":"IPY_MODEL_c4e2782563e44b01b04ce606c7fde729","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"00df77aa9bd342189f62e69a43d608ac":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9bb5fa7547cb4805a98de79d8f2bd08e","max":213450,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bf458a52a1144c2f8244c62cac0254f6","value":213450}},"8659d3eb43c74cb483f84b58da1a3a24":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aa28506a75a849088c91332f6c50a0d3","placeholder":"​","style":"IPY_MODEL_d1950e93a94c497180df2a3843297879","value":" 213k/213k [00:00&lt;00:00, 8.69MB/s]"}},"4a4d219f8753498ba34622010acff94f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d37fa851391d4fb095e45abcf2ab475e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c4e2782563e44b01b04ce606c7fde729":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9bb5fa7547cb4805a98de79d8f2bd08e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf458a52a1144c2f8244c62cac0254f6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"aa28506a75a849088c91332f6c50a0d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d1950e93a94c497180df2a3843297879":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8db7c9b5d50b45b89009a086f08a139c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dd89289a1d35458282b8563f8b7d4ad6","IPY_MODEL_22620ee4e86c4a47ad32c141828fd3f8","IPY_MODEL_bcac8fac84ec46be8a4bb3580ff085f0"],"layout":"IPY_MODEL_f91a4c29fa9f48e48b0da241752ce2db"}},"dd89289a1d35458282b8563f8b7d4ad6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a6aa65cbd03c4af09e4831977365c609","placeholder":"​","style":"IPY_MODEL_8d9710f7fb3145c6b73110df700f3a83","value":"Downloading (…)/main/tokenizer.json: 100%"}},"22620ee4e86c4a47ad32c141828fd3f8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9b0f4a8bf10648d6884a99d612e6708b","max":435797,"min":0,"orientation":"horizontal","style":"IPY_MODEL_00378bd547b84af881629dde87b5a670","value":435797}},"bcac8fac84ec46be8a4bb3580ff085f0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_431e33cc1b28443482d6766dd8884ffc","placeholder":"​","style":"IPY_MODEL_3d0b80e0522c4a6ebdf40ccade997536","value":" 436k/436k [00:00&lt;00:00, 27.4MB/s]"}},"f91a4c29fa9f48e48b0da241752ce2db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a6aa65cbd03c4af09e4831977365c609":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d9710f7fb3145c6b73110df700f3a83":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9b0f4a8bf10648d6884a99d612e6708b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"00378bd547b84af881629dde87b5a670":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"431e33cc1b28443482d6766dd8884ffc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d0b80e0522c4a6ebdf40ccade997536":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"633f17b82e0140d498f35c388f0e5033":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_adf572ad55eb4f258e195c04de0efe51","IPY_MODEL_26f1a087b1744ac68fcef8f49591975e","IPY_MODEL_68181f48b0dd45ccbc6e52bb5c2c8147"],"layout":"IPY_MODEL_37a7182c3cd14490a7158230b835d4c6"}},"adf572ad55eb4f258e195c04de0efe51":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_514844830f1a4186acad49ee3865b5ff","placeholder":"​","style":"IPY_MODEL_abdd64e73e7347588eb5a5d54dee0479","value":"Downloading (…)lve/main/config.json: 100%"}},"26f1a087b1744ac68fcef8f49591975e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f0525a1b6399425ab3a0478b65341df2","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_edabb142ba794c598e8a37f48d092acb","value":570}},"68181f48b0dd45ccbc6e52bb5c2c8147":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_89a39a10da394e81be0de8693d57a1ef","placeholder":"​","style":"IPY_MODEL_c534d90e58a64e70b7d204d8ab776772","value":" 570/570 [00:00&lt;00:00, 45.0kB/s]"}},"37a7182c3cd14490a7158230b835d4c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"514844830f1a4186acad49ee3865b5ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"abdd64e73e7347588eb5a5d54dee0479":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f0525a1b6399425ab3a0478b65341df2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"edabb142ba794c598e8a37f48d092acb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"89a39a10da394e81be0de8693d57a1ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c534d90e58a64e70b7d204d8ab776772":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["!pip install transformers spacy\n","! python -m spacy download en_core_web_trf\n","!apt install subversion\n","!mkdir data\n","!svn checkout https://github.com/ChanCheeKean/datasets/trunk/nlp data"],"metadata":{"id":"vmy0lAPLBqwK"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JEY_jlQQR9SP","scrolled":true},"source":["import os\n","import numpy as np\n","import pandas as pd\n","import random\n","import matplotlib.pyplot as plt\n","import spacy, nltk, re\n","from nltk.stem import WordNetLemmatizer\n","from nltk.corpus import stopwords\n","from pickle import dump, load\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.preprocessing import text, sequence\n","from tensorflow.keras.layers import Dropout, Dense, Input, Activation, LSTM, Embedding, TimeDistributed, MaxPooling1D\n","from tensorflow.keras.models import Model, Sequential, load_model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 1) LSTM NER"],"metadata":{"id":"wOUPH_t753Qj"}},{"cell_type":"code","metadata":{"id":"k8RBOgTLDLfX"},"source":["resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n","tf.config.experimental_connect_to_cluster(resolver)\n","# This is the TPU initialization code that has to be at the beginning.\n","tf.tpu.experimental.initialize_tpu_system(resolver)\n","print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n","strategy = tf.distribute.TPUStrategy(resolver)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xoH6yBWVfzTb"},"source":["## 1.1 Data loading"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":241},"id":"cS575LUvRw29","executionInfo":{"status":"ok","timestamp":1657956682538,"user_tz":-480,"elapsed":1178,"user":{"displayName":"Kean Chan","userId":"05792587367281359063"}},"outputId":"b47aa149-1240-4912-e61a-9f208a7fd694"},"source":["data = pd.read_csv(\"data/ner_dataset.csv\", encoding = \"ISO-8859-1\")\n","print(data['Sentence #'].unique())\n","data.head()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['Sentence: 1' nan 'Sentence: 2' ... 'Sentence: 47957' 'Sentence: 47958'\n"," 'Sentence: 47959']\n"]},{"output_type":"execute_result","data":{"text/plain":["    Sentence #           Word  POS Tag\n","0  Sentence: 1      Thousands  NNS   O\n","1          NaN             of   IN   O\n","2          NaN  demonstrators  NNS   O\n","3          NaN           have  VBP   O\n","4          NaN        marched  VBN   O"],"text/html":["\n","  <div id=\"df-1f3261ec-8e37-418b-928e-6177824387c7\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sentence #</th>\n","      <th>Word</th>\n","      <th>POS</th>\n","      <th>Tag</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Sentence: 1</td>\n","      <td>Thousands</td>\n","      <td>NNS</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>NaN</td>\n","      <td>of</td>\n","      <td>IN</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>NaN</td>\n","      <td>demonstrators</td>\n","      <td>NNS</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>NaN</td>\n","      <td>have</td>\n","      <td>VBP</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>NaN</td>\n","      <td>marched</td>\n","      <td>VBN</td>\n","      <td>O</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1f3261ec-8e37-418b-928e-6177824387c7')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-1f3261ec-8e37-418b-928e-6177824387c7 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-1f3261ec-8e37-418b-928e-6177824387c7');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"5h8XPLogRw2-"},"source":["with open('data/large/words.txt') as f:\n","    vocab = [sent for sent in f.read().splitlines()]\n","\n","with open('data/large/tags.txt') as f:\n","    tag = [sent for sent in f.read().splitlines()]\n","\n","with open('data/large/train/sentences.txt') as f:\n","    train_x = [sent for sent in f.read().splitlines()]\n","\n","with open('data/large/train/labels.txt') as f:\n","    train_y = [sent for sent in f.read().splitlines()]\n","\n","with open('data/large/val/sentences.txt') as f:\n","    val_x = [sent for sent in f.read().splitlines()]\n","\n","with open('data/large/val/labels.txt') as f:\n","    val_y = [sent for sent in f.read().splitlines()]\n","\n","with open('data/large/test/sentences.txt') as f:\n","    test_x = [sent for sent in f.read().splitlines()]\n","\n","with open('data/large/test/labels.txt') as f:\n","    test_y = [sent for sent in f.read().splitlines()]"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(len(vocab))\n","print(vocab[100])\n","print(tag)\n","\n","# check train count\n","print(len(train_x))\n","print(len(train_y))\n","print(train_x[100])\n","print(train_y[100])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GrUZP_jS62Gy","executionInfo":{"status":"ok","timestamp":1657956802563,"user_tz":-480,"elapsed":4,"user":{"displayName":"Kean Chan","userId":"05792587367281359063"}},"outputId":"c7b19588-ad02-4220-bbf4-7e2076d80ae3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["35180\n","Energy\n","['O', 'B-geo', 'B-gpe', 'B-per', 'I-geo', 'B-org', 'I-org', 'B-tim', 'B-art', 'I-art', 'I-per', 'I-gpe', 'I-tim', 'B-nat', 'B-eve', 'I-eve', 'I-nat']\n","33570\n","33570\n","The Pakistani military launched its offensive in Orakzai to hunt Taliban insurgents .\n","O B-gpe O O O O O B-geo O O B-org O O\n"]}]},{"cell_type":"code","metadata":{"id":"482m_M7JRw2_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657957535536,"user_tz":-480,"elapsed":3920,"user":{"displayName":"Kean Chan","userId":"05792587367281359063"}},"outputId":"1bc7f9dc-431a-4a6c-b0f1-4d1963ea246c"},"source":["# tokenized and one hot with keras text\n","tokenizer_x = text.Tokenizer(oov_token='UNK')\n","tokenizer_x.fit_on_texts(vocab)\n","tokenizer_y = text.Tokenizer(lower=False, filters=[])\n","tokenizer_y.fit_on_texts(tag)\n","\n","print(\"Original Text:\")\n","print(train_x[0])\n","print(train_y[0])\n","\n","# label encoder\n","train_x_token = tokenizer_x.texts_to_sequences(train_x)\n","train_y_token = tokenizer_y.texts_to_sequences(train_y)\n","val_x_token = tokenizer_x.texts_to_sequences(val_x)\n","val_y_token = tokenizer_y.texts_to_sequences(val_y)\n","test_x_token = tokenizer_x.texts_to_sequences(test_x)\n","test_y_token = tokenizer_y.texts_to_sequences(test_y)\n","\n","print(\"\\nAfter Label Encoder:\")\n","print(train_x_token[0])\n","print(train_y_token[0])\n","\n","# padding\n","train_x_token = sequence.pad_sequences(train_x_token, padding='post', truncating='post', maxlen=30)\n","val_x_token = sequence.pad_sequences(val_x_token, padding='post', truncating='post', maxlen=30)\n","test_x_token = sequence.pad_sequences(test_x_token, padding='post', truncating='post', maxlen=30)\n","train_y_token = sequence.pad_sequences(train_y_token, padding='post', truncating='post', maxlen=30)\n","val_y_token = sequence.pad_sequences(val_y_token, padding='post', truncating='post', maxlen=30)\n","test_y_token = sequence.pad_sequences(test_y_token, padding='post', truncating='post', maxlen=30)\n","\n","print(\"\\nAfter Padding:\")\n","print(train_x_token[0])\n","print(train_y_token[0])\n","\n","# one hot of y --> sparse\n","train_y_token = tf.one_hot(train_y_token, len(tokenizer_y.index_word))\n","val_y_token = tf.one_hot(val_y_token, len(tokenizer_y.index_word))\n","test_y_token = tf.one_hot(test_y_token, len(tokenizer_y.index_word))\n","\n","print(\"\\nAfter Onehot Encoder:\")\n","print(train_x_token[0])\n","print(train_y_token[0])\n","print(train_x_token.shape)\n","print(train_y_token.shape)\n","\n","print(\"\\nTokenizer Index:\")\n","print(tokenizer_x.index_word[182])\n","print(tokenizer_x.index_word[1])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Original Text:\n","Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country .\n","O O O O O O B-geo O O O O O B-geo O O O O O B-gpe O O O O O\n","\n","After Label Encoder:\n","[1493, 95, 1494, 815, 4765, 816, 1495, 31, 1496, 181, 96, 47, 249, 48, 1497, 181, 4766, 95, 298, 1498, 1499, 1500, 182]\n","[1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1]\n","\n","After Padding:\n","[1493   95 1494  815 4765  816 1495   31 1496  181   96   47  249   48\n"," 1497  181 4766   95  298 1498 1499 1500  182    0    0    0    0    0\n","    0    0]\n","[1 1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 3 1 1 1 1 1 0 0 0 0 0 0]\n","\n","After Onehot Encoder:\n","[1493   95 1494  815 4765  816 1495   31 1496  181   96   47  249   48\n"," 1497  181 4766   95  298 1498 1499 1500  182    0    0    0    0    0\n","    0    0]\n","tf.Tensor(\n","[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]], shape=(30, 17), dtype=float32)\n","(33570, 30)\n","(33570, 30, 17)\n","\n","Tokenizer Index:\n","country\n","UNK\n"]}]},{"cell_type":"markdown","metadata":{"id":"IY6BTBjunCt1"},"source":["The tag_map corresponds to one of the possible tags a word can have. Run the cell below to see the possible classes you will be predicting. The prepositions in the tags mean:\n","* I: Token is inside an entity.\n","* B: Token begins an entity."]},{"cell_type":"markdown","metadata":{"id":"3F1sUP_MnCt5"},"source":["So the coding scheme that tags the entities is a minimal one where B- indicates the first token in a multi-token entity, and I- indicates one in the middle of a multi-token entity. If you had the sentence\n","\n","**\"Sharon flew to Miami on Friday\"**\n","\n","the outputs would look like:\n","\n","```\n","Sharon B-per\n","flew   O\n","to     O\n","Miami  B-geo\n","on     O\n","Friday B-tim\n","```\n","\n","your tags would reflect three tokens beginning with B-, since there are no multi-token entities in the sequence. But if you added Sharon's last name to the sentence:\n","\n","**\"Sharon Floyd flew to Miami on Friday\"**\n","\n","```\n","Sharon B-per\n","Floyd  I-per\n","flew   O\n","to     O\n","Miami  B-geo\n","on     O\n","Friday B-tim\n","```\n","\n","then your tags would change to show first \"Sharon\" as B-per, and \"Floyd\" as I-per, where I- indicates an inner token in a multi-token sequence."]},{"cell_type":"markdown","metadata":{"id":"4SWxKhkVLr3P"},"source":["## 1.2 Model Building"]},{"cell_type":"code","metadata":{"id":"FxXGn1cMRw3C"},"source":["def lstm_model(n_x, n_y, n_h, vocab_size, emb_dim):\n","    i = Input(shape=(n_x, )) # (m, n_x)\n","    x = Embedding(vocab_size + 1, emb_dim)(i) # (m, vocab_len, emb_dim)\n","    x = LSTM(n_h, return_sequences=True)(x) # (m, vocab_len, n_h)\n","    x = Dropout(0.5)(x) # (m, vocab_len, n_h)\n","    x = LSTM(n_h, return_sequences=True)(x) # (m, vocab_len, n_h)\n","    x = TimeDistributed(Dense(n_y, activation='softmax'))(x) # (m, vocab_len, n_y)\n","    model = Model(i, x)\n","    return model\n","\n","tf.keras.backend.clear_session()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"Q4wl8ulbRw3C","executionInfo":{"status":"ok","timestamp":1620059764493,"user_tz":-480,"elapsed":1885,"user":{"displayName":"Chan Chee Kean","photoUrl":"","userId":"05792587367281359063"}},"outputId":"0c237b33-d979-4d52-dfa8-546cbb207d86"},"source":["with strategy.scope():\n","  model = lstm_model(train_x_token.shape[1], tokenizer_y.document_count, 128, tokenizer_x.document_count, 50)\n","  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, 30)]              0         \n","_________________________________________________________________\n","embedding (Embedding)        (None, 30, 50)            1759050   \n","_________________________________________________________________\n","lstm (LSTM)                  (None, 30, 128)           91648     \n","_________________________________________________________________\n","dropout (Dropout)            (None, 30, 128)           0         \n","_________________________________________________________________\n","lstm_1 (LSTM)                (None, 30, 128)           131584    \n","_________________________________________________________________\n","time_distributed (TimeDistri (None, 30, 17)            2193      \n","=================================================================\n","Total params: 1,984,475\n","Trainable params: 1,984,475\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"XeJc5kRCRw3D","executionInfo":{"status":"ok","timestamp":1620059924725,"user_tz":-480,"elapsed":63386,"user":{"displayName":"Chan Chee Kean","photoUrl":"","userId":"05792587367281359063"}},"outputId":"6e1bb466-343f-4824-c826-49b26153c49e"},"source":["r = model.fit(train_x_token, train_y_token, batch_size=64, epochs=5, validation_data=(val_x_token, val_y_token))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/5\n","525/525 [==============================] - 13s 24ms/step - loss: 0.2110 - accuracy: 0.9332 - val_loss: 0.2872 - val_accuracy: 0.9133\n","Epoch 2/5\n","525/525 [==============================] - 12s 24ms/step - loss: 0.2006 - accuracy: 0.9364 - val_loss: 0.2904 - val_accuracy: 0.9147\n","Epoch 3/5\n","525/525 [==============================] - 12s 24ms/step - loss: 0.1900 - accuracy: 0.9397 - val_loss: 0.2897 - val_accuracy: 0.9137\n","Epoch 4/5\n","525/525 [==============================] - 12s 23ms/step - loss: 0.1810 - accuracy: 0.9426 - val_loss: 0.3021 - val_accuracy: 0.9145\n","Epoch 5/5\n","525/525 [==============================] - 12s 24ms/step - loss: 0.1735 - accuracy: 0.9448 - val_loss: 0.3066 - val_accuracy: 0.9144\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":282},"id":"i0IJFi8SRw3D","executionInfo":{"status":"ok","timestamp":1620059925335,"user_tz":-480,"elapsed":63694,"user":{"displayName":"Chan Chee Kean","photoUrl":"","userId":"05792587367281359063"}},"outputId":"4a83ac43-3d4a-411d-ed9d-125d99ec3502"},"source":["plt.plot(r.history['accuracy'], label='acc')\n","plt.plot(r.history['val_accuracy'], label='val_acc')\n","plt.legend()\n","plt.show"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<function matplotlib.pyplot.show>"]},"metadata":{"tags":[]},"execution_count":22},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"c4r-gXOZLr3j"},"source":["## 1.3 Evaluation"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2kBvRvr2Rw3E","executionInfo":{"status":"ok","timestamp":1620059926822,"user_tz":-480,"elapsed":64489,"user":{"displayName":"Chan Chee Kean","photoUrl":"","userId":"05792587367281359063"}},"outputId":"d876a58a-0fc0-43c1-cc01-57674df89987"},"source":["loss, acc = model.evaluate(test_x_token, test_y_token, batch_size=128)\n","print(acc)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["57/57 [==============================] - 2s 19ms/step - loss: 0.3009 - accuracy: 0.9154\n","0.9153785109519958\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0K4SyB20cHRf","scrolled":true},"source":["def predict(sentence, model):\n","    tokenized_sent = tokenizer_x.texts_to_sequences(sentence)\n","    tokenized_sent = sequence.pad_sequences(tokenized_sent, padding='post', truncating='post', maxlen=30)\n","    pred = model.predict(tokenized_sent)\n","    pred = np.argmax(pred, axis=-1)\n","    pred_lis = []\n","    for out in pred:\n","        pred = [tokenizer_y.index_word.get(x) for x in out]\n","        pred_lis.append(pred)\n","    return pred_lis"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vLZCHoiULr3u","scrolled":true},"source":["# New york times news:\n","sentence = [\"Peter Navarro, the White House director of trade and manufacturing policy of U.S, \\\n","said in an interview on Sunday morning that the White House was working to prepare for \\\n","the possibility of a second wave of the coronavirus in the fall, though he said it wouldn’t necessarily come\"]\n","\n","predictions = predict(sentence, model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GA9J20PWRw3F","executionInfo":{"status":"ok","timestamp":1620059928870,"user_tz":-480,"elapsed":65546,"user":{"displayName":"Chan Chee Kean","photoUrl":"","userId":"05792587367281359063"}},"outputId":"b67ae15d-6376-4b8f-8a11-58b197c008d1"},"source":["for x, y in zip(sentence[0].split(' '), predictions[0]):\n","    if y != 'O':\n","        print(x, y)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Peter B-per\n","Navarro, I-per\n","White B-org\n","House I-org\n","director I-org\n","said B-geo\n","morning B-tim\n","that I-tim\n","House B-org\n","was I-org\n"],"name":"stdout"}]},{"cell_type":"markdown","source":["# 2) NER (Transformer)\n","\n","[Named Entity Recognition with BERT in PyTorch](https://towardsdatascience.com/named-entity-recognition-with-bert-in-pytorch-a454405e0b6a)"],"metadata":{"id":"rCi0zgJj57_B"}},{"cell_type":"code","source":["from transformers import BertTokenizerFast\n","from transformers import BertForTokenClassification\n","from torch.utils.data import DataLoader\n","import torch\n","from tqdm import tqdm"],"metadata":{"id":"s3Sx8c0DCLTM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open('data/large/train/sentences.txt') as f:\n","    train_x = [sent for sent in f.read().splitlines()]\n","\n","with open('data/large/train/labels.txt') as f:\n","    train_y = [sent for sent in f.read().splitlines()]\n","\n","with open('data/large/val/sentences.txt') as f:\n","    val_x = [sent for sent in f.read().splitlines()]\n","\n","with open('data/large/val/labels.txt') as f:\n","    val_y = [sent for sent in f.read().splitlines()]\n","\n","# check train count\n","print(len(train_x))\n","print(len(train_y))\n","print(train_x[100])\n","print(train_y[100])\n","\n","train_y = [i.split() for i in train_y]\n","val_y = [i.split() for i in val_y]\n","\n","# Check how many labels are there in the dataset\n","unique_labels = set()\n","\n","for lb in train_y:\n","     [unique_labels.add(i) for i in lb if i not in unique_labels]\n","print(unique_labels)\n","\n","# Map each label into its id representation and vice versa\n","labels_to_ids = {k: v for v, k in enumerate(sorted(unique_labels))}\n","ids_to_labels = {v: k for v, k in enumerate(sorted(unique_labels))}\n","print(labels_to_ids)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_fNbMvCr5-NX","executionInfo":{"status":"ok","timestamp":1694842716964,"user_tz":-480,"elapsed":1591,"user":{"displayName":"Kean Chan","userId":"05792587367281359063"}},"outputId":"2f866cf0-5456-45c4-e319-98b8f2115977"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["33570\n","33570\n","The Pakistani military launched its offensive in Orakzai to hunt Taliban insurgents .\n","O B-gpe O O O O O B-geo O O B-org O O\n","{'B-nat', 'I-eve', 'B-tim', 'B-geo', 'I-org', 'O', 'I-gpe', 'I-tim', 'B-org', 'I-art', 'B-gpe', 'B-per', 'B-art', 'I-geo', 'B-eve', 'I-per', 'I-nat'}\n","{'B-art': 0, 'B-eve': 1, 'B-geo': 2, 'B-gpe': 3, 'B-nat': 4, 'B-org': 5, 'B-per': 6, 'B-tim': 7, 'I-art': 8, 'I-eve': 9, 'I-geo': 10, 'I-gpe': 11, 'I-nat': 12, 'I-org': 13, 'I-per': 14, 'I-tim': 15, 'O': 16}\n"]}]},{"cell_type":"code","source":["tokenizer = BertTokenizerFast.from_pretrained('bert-base-cased')\n","text_tokenized = tokenizer(train_x[0], padding='max_length', max_length=64, truncation=True, return_tensors=\"pt\")\n","print(text_tokenized)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":336,"referenced_widgets":["a388e0621cf7472a8286c9e8c4d30531","e0f5db3629ff46e1bfbf663e5b814429","0f90bc66b907499aaccf8443ddeb04bf","17eb5eaa7dfb4b1d870700d6c9e68cb0","a99c0a38a41e471c90e76beaa1fdf7f9","e7b68a71b8604724803d2d1be961e9f6","8393e7d1d9ac4e70b81302616de6db95","f9a472f636584b308574b46ffd2592ba","f68b98c41b50428f8698ed7b9fc0c14a","78ee3e24cfbd40579e842d65794cf7d5","bd06bbfbb8a2491e86b8c3a335a5bead","bf139f023c1f41c188e9f80ccda80651","2558eeab980b4052bccfdfdd075df31e","00df77aa9bd342189f62e69a43d608ac","8659d3eb43c74cb483f84b58da1a3a24","4a4d219f8753498ba34622010acff94f","d37fa851391d4fb095e45abcf2ab475e","c4e2782563e44b01b04ce606c7fde729","9bb5fa7547cb4805a98de79d8f2bd08e","bf458a52a1144c2f8244c62cac0254f6","aa28506a75a849088c91332f6c50a0d3","d1950e93a94c497180df2a3843297879","8db7c9b5d50b45b89009a086f08a139c","dd89289a1d35458282b8563f8b7d4ad6","22620ee4e86c4a47ad32c141828fd3f8","bcac8fac84ec46be8a4bb3580ff085f0","f91a4c29fa9f48e48b0da241752ce2db","a6aa65cbd03c4af09e4831977365c609","8d9710f7fb3145c6b73110df700f3a83","9b0f4a8bf10648d6884a99d612e6708b","00378bd547b84af881629dde87b5a670","431e33cc1b28443482d6766dd8884ffc","3d0b80e0522c4a6ebdf40ccade997536","633f17b82e0140d498f35c388f0e5033","adf572ad55eb4f258e195c04de0efe51","26f1a087b1744ac68fcef8f49591975e","68181f48b0dd45ccbc6e52bb5c2c8147","37a7182c3cd14490a7158230b835d4c6","514844830f1a4186acad49ee3865b5ff","abdd64e73e7347588eb5a5d54dee0479","f0525a1b6399425ab3a0478b65341df2","edabb142ba794c598e8a37f48d092acb","89a39a10da394e81be0de8693d57a1ef","c534d90e58a64e70b7d204d8ab776772"]},"id":"YaBhUWf3B8tG","executionInfo":{"status":"ok","timestamp":1694842720626,"user_tz":-480,"elapsed":3129,"user":{"displayName":"Kean Chan","userId":"05792587367281359063"}},"outputId":"d05b4fc8-88f4-4ea5-834e-94d7ae342db4"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a388e0621cf7472a8286c9e8c4d30531"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf139f023c1f41c188e9f80ccda80651"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8db7c9b5d50b45b89009a086f08a139c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"633f17b82e0140d498f35c388f0e5033"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["{'input_ids': tensor([[  101, 26159,  1104,  8568,  4487,  5067,  1138,  9639,  1194,  1498,\n","          1106,  5641,  1103,  1594,  1107,  5008,  1105,  4555,  1103, 10602,\n","          1104,  1418,  2830,  1121,  1115,  1583,   119,   102,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n"]}]},{"cell_type":"markdown","source":["**Adjusting Label After Tokenization** is needed because the length of the sequence is no longer matching the length of the original label.\n","\n","*   The addition of special tokens from BERT such as [CLS], [SEP], and [PAD]\n","*   The fact that some tokens are splitted into sub-words.\n","\n","The consequence: sequence length after tokenization != length of the initial label."],"metadata":{"id":"iSpA48YdC89j"}},{"cell_type":"code","source":["# SEP, CLS, PAD token is none. SPlitted word share same ids\n","print(text_tokenized.word_ids()[:30])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BeEN5VZIC9VS","executionInfo":{"status":"ok","timestamp":1694842720627,"user_tz":-480,"elapsed":7,"user":{"displayName":"Kean Chan","userId":"05792587367281359063"}},"outputId":"048383b9-e6d2-47bb-e02e-6b178d0dc0fc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[None, 0, 1, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, None, None, None]\n"]}]},{"cell_type":"markdown","source":["Either Way:\n","\n","1.   Only provide a label to the first sub-word of each splitted token. The continuation of the sub-word then will simply have ‘-100’ as a label. All tokens that don’t have word_ids will also be labeled with ‘-100’. Set `label_all_tokens` to False\n","2.   Provide the same label among all of the sub-words that belong to the same token. All tokens that don’t have word_ids will be labeled with ‘-100’."],"metadata":{"id":"FNsEiLYQEM6O"}},{"cell_type":"code","source":["def align_label(texts, labels, tokenized_inputs=None, label_all_tokens=False):\n","    '''if label_all_tokens=True: Provide the same label among all of the sub-words'''\n","\n","    if tokenized_inputs is None:\n","        tokenized_inputs = tokenizer(texts, padding='max_length', max_length=64, truncation=True)\n","    word_ids = tokenized_inputs.word_ids()\n","    previous_word_idx = None\n","    label_ids = []\n","\n","    for word_idx in word_ids:\n","\n","        if word_idx is None:\n","            label_ids.append(-100)\n","\n","        elif word_idx != previous_word_idx:\n","            try:\n","                label_ids.append(labels_to_ids[labels[word_idx]])\n","            except:\n","                label_ids.append(-100)\n","\n","        # if sub-word\n","        else:\n","            try:\n","                label_ids.append(labels_to_ids[labels[word_idx]] if label_all_tokens else -100)\n","            except:\n","                label_ids.append(-100)\n","        previous_word_idx = word_idx\n","\n","    return label_ids\n","\n","print(train_y[100])\n","new_label = align_label(train_x[100], train_y[100])\n","print(new_label)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BOl_UhBfDteG","executionInfo":{"status":"ok","timestamp":1694842790027,"user_tz":-480,"elapsed":3,"user":{"displayName":"Kean Chan","userId":"05792587367281359063"}},"outputId":"fdaff532-8502-4efc-b54c-189060613d86"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['O', 'B-gpe', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'B-org', 'O', 'O']\n","[-100, 16, 3, 16, 16, 16, 16, 16, 2, -100, -100, 16, 16, 5, 16, 16, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n"]}]},{"cell_type":"code","source":["# torch dataset\n","class BertDataSet(torch.utils.data.Dataset):\n","\n","    def __init__(self, txt, lb):\n","        self.texts = tokenizer(\n","            txt,\n","            padding='max_length',\n","            max_length=64,\n","            truncation=True,\n","            return_tensors=\"pt\"\n","        )\n","        self.labels = [align_label(i, j) for i, j in zip(txt, lb)]\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, idx):\n","        item = {key: val[idx].clone().detach() for key, val in self.texts.items()}\n","        item['labels'] = torch.LongTensor(self.labels[idx])\n","        return item"],"metadata":{"id":"_79ur136GpGN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class BertModel(torch.nn.Module):\n","    def __init__(self):\n","        super(BertModel, self).__init__()\n","        self.bert = BertForTokenClassification.from_pretrained('bert-base-cased', num_labels=len(unique_labels))\n","\n","    def forward(self, input_id, mask, label):\n","        # it returns both embedding and loss due to BertForTokenClassification\n","        output = self.bert(input_ids=input_id, attention_mask=mask, labels=label, return_dict=False)\n","        return output"],"metadata":{"id":"M-UGjuAXI547"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_label = train_y[:8]\n","train_data = train_x[:8]\n","train_label = [align_label(i, j) for i, j in zip(train_data, train_label)]\n","train_data = tokenizer(train_data, padding='max_length', max_length=64, truncation=True, return_tensors=\"pt\")\n","mask = train_data['attention_mask']\n","input_id = train_data['input_ids']\n","test_model = BertModel()\n","loss, logits = test_model(input_id, mask, torch.tensor(train_label))\n","\n","print(loss)\n","print(logits.size())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T6CCPFYFK_IT","executionInfo":{"status":"ok","timestamp":1694842991261,"user_tz":-480,"elapsed":5374,"user":{"displayName":"Kean Chan","userId":"05792587367281359063"}},"outputId":"b4129bdf-620f-4832-dcb6-f676e83ea217"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["tensor(2.7760, grad_fn=<NllLossBackward0>)\n","torch.Size([8, 64, 17])\n"]}]},{"cell_type":"code","source":["# the criterion in BertForTokenClassification model\n","criterion = torch.nn.CrossEntropyLoss(ignore_index=-100)\n","truth = torch.tensor(train_label)\n","truth = truth.view(truth.shape[0] * truth.shape[1]).type(torch.LongTensor)\n","logits = logits.view(-1, logits.shape[2]).type(torch.FloatTensor)\n","criterion(logits, truth)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7sfwoOLMZ7ym","executionInfo":{"status":"ok","timestamp":1694842991262,"user_tz":-480,"elapsed":11,"user":{"displayName":"Kean Chan","userId":"05792587367281359063"}},"outputId":"9d7deeff-20f5-481d-f2dd-79a814098673"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(2.7760, grad_fn=<NllLossBackward0>)"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["train_dataset = BertDataSet(train_x, train_y)\n","val_dataset = BertDataSet(val_x, val_y)\n","\n","train_dataloader = DataLoader(train_dataset, num_workers=4, batch_size=64, shuffle=True)\n","val_dataloader = DataLoader(val_dataset, num_workers=4, batch_size=64)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eUN540N8cAzi","executionInfo":{"status":"ok","timestamp":1694843051844,"user_tz":-480,"elapsed":18284,"user":{"displayName":"Kean Chan","userId":"05792587367281359063"}},"outputId":"fdb4f054-3135-4ab8-fbb7-b83e6ba6b8e8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]}]},{"cell_type":"code","source":["train_label = torch.randint(0, 17, (32, 64))\n","logits = torch.randn(32, 64, 17)\n","mask = (train_label != -100)\n","\n","filtered_logits = logits[mask]\n","\n","print(filtered_logits.size())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"neAutCGCnrT6","executionInfo":{"status":"ok","timestamp":1694845515970,"user_tz":-480,"elapsed":6,"user":{"displayName":"Kean Chan","userId":"05792587367281359063"}},"outputId":"85a4944a-d0eb-4fec-b513-ba76c0c330b3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2048, 17])\n"]}]},{"cell_type":"code","source":["mask.size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mePzGsrgqlqj","executionInfo":{"status":"ok","timestamp":1694845539144,"user_tz":-480,"elapsed":500,"user":{"displayName":"Kean Chan","userId":"05792587367281359063"}},"outputId":"6460cf8a-b5f4-4675-a8e5-1f5ef994c050"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([32, 64])"]},"metadata":{},"execution_count":52}]},{"cell_type":"code","source":["def train_loop(model, train_x, train_y, val_x, val_y):\n","\n","    train_dataset = BertDataSet(train_x, train_y,)\n","    val_dataset = BertDataSet(val_x, val_y)\n","\n","    train_dataloader = DataLoader(train_dataset, num_workers=2, batch_size=32, shuffle=True)\n","    val_dataloader = DataLoader(val_dataset, num_workers=2, batch_size=32)\n","\n","    use_cuda = torch.cuda.is_available()\n","    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","    print(f\"Device Used: {device}\")\n","\n","    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n","\n","    if use_cuda:\n","        model = model.cuda()\n","\n","    best_acc = 0\n","    best_loss = 1000\n","\n","    for epoch_num in range(EPOCHS):\n","\n","        total_acc_train = 0\n","        total_loss_train = 0\n","        model.train()\n","\n","        for train_data in train_dataloader:\n","            train_label = train_data['labels'].to(device)\n","            mask = train_data['attention_mask'].to(device)\n","            input_id = train_data['input_ids'].to(device)\n","            optimizer.zero_grad()\n","\n","            # logits(m, seq_len, num_class)\n","            loss, logits = model(input_id, mask, train_label)\n","            # (m * seq_len (non -100), num_class)\n","            logits_clean = logits[train_label != -100]\n","            label_clean = train_label[train_label != -100]\n","            # (m * seq_len (non -100))\n","            predictions = logits_clean.argmax(dim=1)\n","\n","            acc = (predictions == label_clean).float().mean()\n","            total_acc_train += acc\n","            total_loss_train += loss.item()\n","            loss.backward()\n","            optimizer.step()\n","\n","        model.eval()\n","\n","        total_acc_val = 0\n","        total_loss_val = 0\n","\n","        for val_data in val_dataloader:\n","\n","            val_label = val_data['labels'].to(device)\n","            mask = val_data['attention_mask'].to(device)\n","            input_id = val_data['input_ids'].to(device)\n","            loss, logits = model(input_id, mask, val_label)\n","\n","            logits_clean = logits[val_label != -100]\n","            label_clean = val_label[val_label != -100]\n","            predictions = logits_clean.argmax(dim=1)\n","\n","            acc = (predictions == label_clean).float().mean()\n","            total_acc_val += acc\n","            total_loss_val += loss.item()\n","\n","        val_accuracy = total_acc_val / len(val_y)\n","        val_loss = total_loss_val / len(val_y)\n","\n","        print(f'Epochs: {epoch_num + 1} | Loss: {total_loss_train / len(train_dataloader): .3f} | Val_Loss: {total_loss_val / len(val_dataloader): .3f} ')\n","        print(f'Accuracy: {total_acc_train / len(train_dataloader): .3f} | Accuracy: {total_acc_val / len(val_dataloader): .3f}')\n","\n","LEARNING_RATE = 5e-5\n","EPOCHS = 5\n","model = BertModel()\n","train_loop(model, train_x, train_y, val_x, val_y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WgF-tx8lJYwX","outputId":"39bfefca-a8aa-4433-cfcc-0e41be88b660"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Device Used: cuda\n"]}]},{"cell_type":"markdown","source":["# 3) NER (Spacy Pipelines)"],"metadata":{"id":"b8hwnAoZhSuG"}},{"cell_type":"code","source":["def spacy_tokenizer(nlp):\n","    ## https://spacy.io/usage/linguistic-features#special-cases\n","    # [$&+,:;=?|'<>.^*()%!-]\n","\n","    # split special characters away from beginning of text\n","    prefixes = nlp.Defaults.prefixes + [\"^[^\\w\\s]\"]\n","    prefix_regex = spacy.util.compile_prefix_regex(prefixes)\n","    nlp.tokenizer.prefix_search = prefix_regex.search\n","\n","    # split special characters away from the end of text\n","    suffixes = nlp.Defaults.suffixes + [\"[^\\w\\s]$\"]\n","    suffix_regex = spacy.util.compile_suffix_regex(suffixes)\n","    nlp.tokenizer.suffix_search = suffix_regex.search\n","\n","    # split special characters in between text\n","    infixes = nlp.Defaults.infixes + [\"[^\\w\\s]\"]\n","    infix_regex = spacy.util.compile_infix_regex(infixes)\n","    nlp.tokenizer.infix_finditer = infix_regex.finditer\n","    return nlp\n","\n","import spacy\n","from spacy.tokens import Doc\n","\n","pre_roberta_nlp = spacy.load(\n","    'en_core_web_trf',\n","    disable=['tagger', 'parser', 'attribute_ruler', 'lemmatizer']\n",")\n","pre_roberta_nlp.add_pipe('sentencizer')\n","sentence = \"I like the ice cream from Brunos.\"\n","\n","# doc = pre_roberta_nlp(Doc(pre_roberta_nlp.vocab, [sentence]))\n","doc = pre_roberta_nlp(sentence)\n","pre_roberta_nlp = spacy_tokenizer(pre_roberta_nlp)\n","\n","# print location and detected brand\n","print([(e.text, e.start_char-e.sent.start_char, e.end_char-e.sent.start_char, e.label_) for e in doc.ents], '\\n')\n","\n","for d in doc:\n","    print(f\"{d.text} | {d.ent_iob_} | {d.ent_type_}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6pxSzrQVhVEg","executionInfo":{"status":"ok","timestamp":1660552325489,"user_tz":-480,"elapsed":4419,"user":{"displayName":"Kean Chan","userId":"05792587367281359063"}},"outputId":"6623c61f-7408-435e-d501-3fddc125a799"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[('Brunos', 26, 32, 'ORG')] \n","\n","I | O | \n","like | O | \n","the | O | \n","ice | O | \n","cream | O | \n","from | O | \n","Brunos | B | ORG\n",". | O | \n"]}]},{"cell_type":"markdown","source":["# 4) GLiNER\n","\n","[GLiNER Repo](https://github.com/urchade/GLiNER/tree/main)"],"metadata":{"id":"y_3eQ1aRa9ZQ"}},{"cell_type":"code","source":["!mkdir data\n","!wget https://huggingface.co/datasets/Universal-NER/Pile-NER-type/resolve/main/train.json?download=true -O ./data/train.json\n","!pip install tqdm transformers flair"],"metadata":{"id":"RitUgUcIcbPx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import sys\n","import json\n","import argparse\n","import re\n","import ast\n","import random\n","from pathlib import Path\n","import yaml\n","from tqdm import tqdm\n","from collections import defaultdict\n","from typing import List, Tuple, Dict, Optional, Union\n","from types import SimpleNamespace\n","import torch\n","from torch import nn\n","import torch.nn.functional as F\n","from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n","from torch.utils.data import DataLoader\n","from transformers import get_cosine_schedule_with_warmup\n","from huggingface_hub import PyTorchModelHubMixin, hf_hub_download\n","from flair.embeddings import TransformerWordEmbeddings\n","from flair.data import Sentence"],"metadata":{"id":"ue2eEeJQa-pP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4.1 Data Processing"],"metadata":{"id":"YEv9jjuCcl76"}},{"cell_type":"code","source":["def load_data(filepath):\n","    \"\"\"Loads data from a JSON file.\"\"\"\n","    with open(filepath, \"r\") as f:\n","        data = json.load(f)\n","    return data\n","\n","def tokenize_text(text):\n","    \"\"\"Tokenizes the input text into a list of tokens.\"\"\"\n","    return re.findall(r\"\\w+(?:[-_]\\w+)*|\\S\", text)\n","\n","def extract_entity_spans(entry):\n","    \"\"\"Extracts entity spans from an entry.\"\"\"\n","    len_start = len(\"What describes \")\n","    len_end = len(\" in the text?\")\n","    entity_types, entity_texts, negative = [], [], []\n","\n","    for c in entry[\"conversations\"]:\n","        if c[\"from\"] == \"human\" and c[\"value\"].startswith(\"Text: \"):\n","            text = c[\"value\"][len(\"Text: \") :]\n","            tokenized_text = tokenize_text(text)\n","        elif c[\"from\"] == \"human\" and c[\"value\"].startswith(\"What describes \"):\n","            entity_type = c[\"value\"][len_start:-len_end]\n","            entity_types.append(entity_type)\n","        elif c[\"from\"] == \"gpt\" and c[\"value\"].startswith(\"[\"):\n","            if c[\"value\"] == \"[]\":\n","                negative.append(entity_types.pop())\n","                continue\n","            texts_ents = ast.literal_eval(c[\"value\"])\n","            entity_texts.extend(texts_ents)\n","            num_repeat = len(texts_ents) - 1\n","            entity_types.extend([entity_types[-1]] * num_repeat)\n","\n","    entity_spans = []\n","    for j, entity_text in enumerate(entity_texts):\n","        entity_tokens = tokenize_text(entity_text)\n","        matches = []\n","\n","        # shift the inde from start to end, check if the word match\n","        for i in range(len(tokenized_text) - len(entity_tokens) + 1):\n","            if (\n","                \" \".join(tokenized_text[i : i + len(entity_tokens)]).lower()\n","                == \" \".join(entity_tokens).lower()\n","            ):\n","                matches.append((i, i + len(entity_tokens) - 1, entity_types[j]))\n","        if matches:\n","            entity_spans.extend(matches)\n","\n","    return {\"tokenized_text\": tokenized_text, \"ner\": entity_spans, \"negative\": negative}\n","\n","def process_data(data):\n","    \"\"\"Processes a list of data entries to extract entity spans.\"\"\"\n","    all_data = [extract_entity_spans(entry) for entry in tqdm(data)]\n","    return all_data\n","\n","def save_data_to_file(data, filepath):\n","    \"\"\"Saves the processed data to a JSON file.\"\"\"\n","    with open(filepath, \"w\") as f:\n","        json.dump(data, f)"],"metadata":{"id":"oSxyGOI2ca4K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### data processing ###\n","data = load_data(\"./data/train.json\")\n","processed_data = process_data(data)\n","save_data_to_file(processed_data, \"./data/pilener_train.json\")\n","print(data[0])"],"metadata":{"id":"UDCBNkwufBzD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4.2 Configuration"],"metadata":{"id":"Wra5L56le6G3"}},{"cell_type":"code","source":["config = SimpleNamespace(\n","      num_steps=1000,\n","      train_batch_size=8,\n","      eval_every=100,\n","      save_directory=\"logs\",\n","      warmup_ratio=0.1,\n","      device=\"cpu\",\n","      lr_encoder=1e-5,\n","      lr_others=5e-5,\n","      freeze_token_rep=False,\n","      # maximum number of entity types\n","      max_types=25,\n","      # shuffle or not entity types\n","      shuffle_types=True,\n","      # randomly drop entity types\n","      random_drop=True,\n","      # ratio of positive/negative types\n","      # 1 mean 50%/50%, 2 mean 33%/66%, 3 mean 25%/75% ...\n","      max_neg_type_ratio=1,\n","      max_len=384,  # maximum sentence length\n","      max_width=12, # n-gram\n","  )"],"metadata":{"id":"dKztNv_ie8Xd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4.3 Data Loading"],"metadata":{"id":"7g86MOTEeSeM"}},{"cell_type":"code","source":["def get_dict(spans, classes_to_id):\n","    dict_tag = defaultdict(int)\n","    for span in spans:\n","        if span[2] in classes_to_id:\n","            dict_tag[(span[0], span[1])] = classes_to_id[span[2]]\n","    return dict_tag\n","\n","def preprocess_spans(tokens, ner, classes_to_id, config):\n","    # truncate long sentence\n","    max_len = config.max_len\n","    if len(tokens) > max_len:\n","        length = max_len\n","        tokens = tokens[:max_len]\n","    else:\n","        length = len(tokens)\n","\n","    # get n-gram span\n","    spans_idx = []\n","    for i in range(length):\n","        spans_idx.extend([(i, i + j) for j in range(config.max_width)])\n","\n","    # convert ner type to id\n","    dict_lab = get_dict(ner, classes_to_id) if ner else defaultdict(int)\n","\n","    # 0 for null labels, -1 for out of span\n","    span_label = torch.LongTensor([dict_lab[i] for i in spans_idx])\n","    spans_idx = torch.LongTensor(spans_idx)\n","    valid_span_mask = spans_idx[:, 1] > length - 1\n","    span_label = span_label.masked_fill(valid_span_mask, -1)\n","\n","    return {\n","        \"tokens\": tokens, # all tokenized words\n","        \"span_idx\": spans_idx, # list of n-gram, len(tokens) * max_width\n","        \"span_label\": span_label, # 0 for no label, -1 for out of sentence\n","        \"seq_length\": length, # tokens length\n","        \"entities\": ner, # golden truth\n","    }\n","\n","def get_negatives(batch_list, sampled_neg=5):\n","    ent_types = []\n","    for b in batch_list:\n","        types = set([el[-1] for el in b[\"ner\"]])\n","        ent_types.extend(list(types))\n","    ent_types = list(set(ent_types))\n","    # sample negatives\n","    random.shuffle(ent_types)\n","    return ent_types[:sampled_neg]\n","\n","\n","def collate_fn(batch_list, entity_types=None, config=None):\n","    # batch_list: list of dict containing tokens, ner\n","\n","    if entity_types is None:\n","        # get negative entity types from other row in the batch\n","        negs = get_negatives(batch_list, 100)\n","\n","        class_to_ids = []\n","        id_to_classes = []\n","\n","        for b in batch_list:\n","            # negs = b[\"negative\"]\n","            random.shuffle(negs)\n","            # negs = negs[:sampled_neg]\n","            max_neg_type_ratio = int(config.max_neg_type_ratio)\n","\n","            if max_neg_type_ratio == 0:\n","                # no negatives\n","                neg_type_ratio = 0\n","                negs_i = []\n","            else:\n","                neg_type_ratio = random.randint(0, max_neg_type_ratio)\n","                negs_i = negs[: len(b[\"ner\"]) * neg_type_ratio]\n","\n","            # this is the list of all possible entity types (positive and negative)\n","            types = list(set([el[-1] for el in b[\"ner\"]] + negs_i))\n","\n","            # shuffle (every epoch)\n","            random.shuffle(types)\n","            if len(types) != 0:\n","                # random drop\n","                if config.random_drop:\n","                    num_ents = random.randint(1, len(types))\n","                    types = types[:num_ents]\n","\n","            # maximum number of entities types\n","            types = types[: int(config.max_types)]\n","\n","            # supervised training\n","            if \"label\" in b:\n","                types = sorted(b[\"label\"])\n","\n","            class_to_id = {k: v for v, k in enumerate(types, start=1)}\n","            id_to_class = {k: v for v, k in class_to_id.items()}\n","            class_to_ids.append(class_to_id)\n","            id_to_classes.append(id_to_class)\n","\n","        batch = [\n","            preprocess_spans(b[\"tokenized_text\"], b[\"ner\"], class_to_ids[i], config=config)\n","            for i, b in enumerate(batch_list)\n","        ]\n","\n","    else:\n","        class_to_ids = {k: v for v, k in enumerate(entity_types, start=1)}\n","        id_to_classes = {k: v for v, k in class_to_ids.items()}\n","        batch = [\n","            preprocess_spans(b[\"tokenized_text\"], b[\"ner\"], class_to_ids, config=config)\n","            for b in batch_list\n","        ]\n","\n","    span_idx = pad_sequence(\n","        [b[\"span_idx\"] for b in batch], batch_first=True, padding_value=0\n","    )\n","\n","    span_label = pad_sequence(\n","        [el[\"span_label\"] for el in batch], batch_first=True, padding_value=-1\n","    )\n","\n","    return {\n","        \"seq_length\": torch.LongTensor([el[\"seq_length\"] for el in batch]),\n","        \"span_idx\": span_idx,\n","        \"tokens\": [el[\"tokens\"] for el in batch],\n","        \"span_mask\": span_label != -1,\n","        \"span_label\": span_label,\n","        \"entities\": [el[\"entities\"] for el in batch],\n","        \"classes_to_id\": class_to_ids,\n","        \"id_to_classes\": id_to_classes,\n","    }\n","\n","\n","def create_dataloader(data, entity_types=None, config=None, **kwargs):\n","    return DataLoader(\n","        data, collate_fn=lambda x: collate_fn(x, entity_types, config=config), **kwargs\n","    )"],"metadata":{"id":"tTcw0b8FdZHe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_path = \"./data/pilener_train.json\"\n","with open(train_path, \"r\") as f:\n","    train_data = json.load(f)\n","train_dataloader = create_dataloader(\n","    train_data, batch_size=config.train_batch_size, config=config, shuffle=True\n",")\n","\n","print(next(iter(train_dataloader)))"],"metadata":{"id":"c7ZNhxtwexfF"},"execution_count":null,"outputs":[]}]}