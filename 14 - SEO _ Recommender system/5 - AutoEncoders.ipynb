{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"5 - AutoEncoders.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"K4f4JG1gdKqj"},"source":["#AutoEncoders"]},{"cell_type":"code","metadata":{"id":"_LvGeU1CeCtg"},"source":["import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.nn.parallel\n","import torch.optim as optim\n","import torch.utils.data\n","from torch.autograd import Variable"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pM04FyMudkoK"},"source":["## Data Loading\n"]},{"cell_type":"code","metadata":{"id":"UJw2p3-Cewo4"},"source":["# We won't be using this dataset.\n","movies = pd.read_csv('ml-1m/movies.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n","users = pd.read_csv('ml-1m/users.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n","ratings = pd.read_csv('ml-1m/ratings.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yTIbE2tkdkwP"},"source":["## Preparing the training set and the test set\n"]},{"cell_type":"code","metadata":{"id":"2usLKJBEgPE2"},"source":["training_set = pd.read_csv('ml-100k/u1.base', delimiter = '\\t')\n","training_set = np.array(training_set, dtype = 'int')\n","test_set = pd.read_csv('ml-100k/u1.test', delimiter = '\\t')\n","test_set = np.array(test_set, dtype = 'int')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zCf8HjSydk4s"},"source":["## Getting the number of users and movies\n"]},{"cell_type":"code","metadata":{"id":"gPaGZqdniC5m"},"source":["nb_users = int(max(max(training_set[:, 0], ), max(test_set[:, 0])))\n","nb_movies = int(max(max(training_set[:, 1], ), max(test_set[:, 1])))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J-w4-hVidlAm"},"source":["## Converting the data into an array with users in lines and movies in columns\n"]},{"cell_type":"code","metadata":{"id":"-wASs2YFiDaa"},"source":["def convert(data):\n","  new_data = []\n","  for id_users in range(1, nb_users + 1):\n","    id_movies = data[:, 1] [data[:, 0] == id_users]\n","    id_ratings = data[:, 2] [data[:, 0] == id_users]\n","    ratings = np.zeros(nb_movies)\n","    ratings[id_movies - 1] = id_ratings\n","    new_data.append(list(ratings))\n","  return new_data\n","training_set = convert(training_set)\n","test_set = convert(test_set)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AMmhuUpldlHo"},"source":["## Converting the data into Torch tensors\n"]},{"cell_type":"code","metadata":{"id":"TwD-KD8yiEEw"},"source":["training_set = torch.FloatTensor(training_set)\n","test_set = torch.FloatTensor(test_set)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6kkL8NkkdlZj"},"source":["## Creating the architecture of the Neural Network\n"]},{"cell_type":"code","metadata":{"id":"oU2nyh76iE6M"},"source":["class SAE(nn.Module):\n","    def __init__(self, ):\n","        super(SAE, self).__init__()\n","        self.fc1 = nn.Linear(nb_movies, 20)\n","        self.fc2 = nn.Linear(20, 10)\n","        self.fc3 = nn.Linear(10, 20)\n","        self.fc4 = nn.Linear(20, nb_movies)\n","        self.activation = nn.Sigmoid()\n","    def forward(self, x):\n","        x = self.activation(self.fc1(x))\n","        x = self.activation(self.fc2(x))\n","        x = self.activation(self.fc3(x))\n","        x = self.fc4(x)\n","        return x\n","sae = SAE()\n","criterion = nn.MSELoss()\n","optimizer = optim.RMSprop(sae.parameters(), lr = 0.01, weight_decay = 0.5)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7gy59alAdloL"},"source":["## Training the SAE\n"]},{"cell_type":"code","metadata":{"id":"FEz9hRaciFTs","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"0f6ed0d0-09c4-46c0-bfe6-70031d76b491"},"source":["nb_epoch = 200\n","for epoch in range(1, nb_epoch + 1):\n","  train_loss = 0\n","  s = 0.\n","  for id_user in range(nb_users):\n","    input = Variable(training_set[id_user]).unsqueeze(0)\n","    target = input.clone()\n","    if torch.sum(target.data > 0) > 0:\n","      output = sae(input)\n","      target.require_grad = False\n","      output[target == 0] = 0\n","      loss = criterion(output, target)\n","      mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n","      loss.backward()\n","      train_loss += np.sqrt(loss.data*mean_corrector)\n","      s += 1.\n","      optimizer.step()\n","  print('epoch: '+str(epoch)+'loss: '+ str(train_loss/s))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["epoch: 1loss: tensor(1.7709)\n","epoch: 2loss: tensor(1.0968)\n","epoch: 3loss: tensor(1.0534)\n","epoch: 4loss: tensor(1.0384)\n","epoch: 5loss: tensor(1.0309)\n","epoch: 6loss: tensor(1.0267)\n","epoch: 7loss: tensor(1.0239)\n","epoch: 8loss: tensor(1.0220)\n","epoch: 9loss: tensor(1.0208)\n","epoch: 10loss: tensor(1.0198)\n","epoch: 11loss: tensor(1.0187)\n","epoch: 12loss: tensor(1.0185)\n","epoch: 13loss: tensor(1.0179)\n","epoch: 14loss: tensor(1.0173)\n","epoch: 15loss: tensor(1.0171)\n","epoch: 16loss: tensor(1.0170)\n","epoch: 17loss: tensor(1.0165)\n","epoch: 18loss: tensor(1.0168)\n","epoch: 19loss: tensor(1.0163)\n","epoch: 20loss: tensor(1.0163)\n","epoch: 21loss: tensor(1.0162)\n","epoch: 22loss: tensor(1.0161)\n","epoch: 23loss: tensor(1.0158)\n","epoch: 24loss: tensor(1.0160)\n","epoch: 25loss: tensor(1.0153)\n","epoch: 26loss: tensor(1.0156)\n","epoch: 27loss: tensor(1.0154)\n","epoch: 28loss: tensor(1.0151)\n","epoch: 29loss: tensor(1.0141)\n","epoch: 30loss: tensor(1.0115)\n","epoch: 31loss: tensor(1.0098)\n","epoch: 32loss: tensor(1.0075)\n","epoch: 33loss: tensor(1.0052)\n","epoch: 34loss: tensor(1.0050)\n","epoch: 35loss: tensor(1.0015)\n","epoch: 36loss: tensor(0.9990)\n","epoch: 37loss: tensor(0.9964)\n","epoch: 38loss: tensor(0.9965)\n","epoch: 39loss: tensor(0.9912)\n","epoch: 40loss: tensor(0.9891)\n","epoch: 41loss: tensor(0.9876)\n","epoch: 42loss: tensor(0.9865)\n","epoch: 43loss: tensor(0.9843)\n","epoch: 44loss: tensor(0.9839)\n","epoch: 45loss: tensor(0.9802)\n","epoch: 46loss: tensor(0.9861)\n","epoch: 47loss: tensor(0.9773)\n","epoch: 48loss: tensor(0.9799)\n","epoch: 49loss: tensor(0.9791)\n","epoch: 50loss: tensor(0.9738)\n","epoch: 51loss: tensor(0.9703)\n","epoch: 52loss: tensor(0.9747)\n","epoch: 53loss: tensor(0.9733)\n","epoch: 54loss: tensor(0.9747)\n","epoch: 55loss: tensor(0.9733)\n","epoch: 56loss: tensor(0.9721)\n","epoch: 57loss: tensor(0.9684)\n","epoch: 58loss: tensor(0.9661)\n","epoch: 59loss: tensor(0.9632)\n","epoch: 60loss: tensor(0.9637)\n","epoch: 61loss: tensor(0.9607)\n","epoch: 62loss: tensor(0.9603)\n","epoch: 63loss: tensor(0.9580)\n","epoch: 64loss: tensor(0.9662)\n","epoch: 65loss: tensor(0.9650)\n","epoch: 66loss: tensor(0.9590)\n","epoch: 67loss: tensor(0.9628)\n","epoch: 68loss: tensor(0.9599)\n","epoch: 69loss: tensor(0.9581)\n","epoch: 70loss: tensor(0.9579)\n","epoch: 71loss: tensor(0.9560)\n","epoch: 72loss: tensor(0.9573)\n","epoch: 73loss: tensor(0.9561)\n","epoch: 74loss: tensor(0.9609)\n","epoch: 75loss: tensor(0.9576)\n","epoch: 76loss: tensor(0.9644)\n","epoch: 77loss: tensor(0.9562)\n","epoch: 78loss: tensor(0.9554)\n","epoch: 79loss: tensor(0.9517)\n","epoch: 80loss: tensor(0.9521)\n","epoch: 81loss: tensor(0.9521)\n","epoch: 82loss: tensor(0.9545)\n","epoch: 83loss: tensor(0.9510)\n","epoch: 84loss: tensor(0.9508)\n","epoch: 85loss: tensor(0.9490)\n","epoch: 86loss: tensor(0.9484)\n","epoch: 87loss: tensor(0.9464)\n","epoch: 88loss: tensor(0.9482)\n","epoch: 89loss: tensor(0.9484)\n","epoch: 90loss: tensor(0.9477)\n","epoch: 91loss: tensor(0.9449)\n","epoch: 92loss: tensor(0.9460)\n","epoch: 93loss: tensor(0.9437)\n","epoch: 94loss: tensor(0.9432)\n","epoch: 95loss: tensor(0.9417)\n","epoch: 96loss: tensor(0.9429)\n","epoch: 97loss: tensor(0.9417)\n","epoch: 98loss: tensor(0.9420)\n","epoch: 99loss: tensor(0.9398)\n","epoch: 100loss: tensor(0.9405)\n","epoch: 101loss: tensor(0.9385)\n","epoch: 102loss: tensor(0.9393)\n","epoch: 103loss: tensor(0.9380)\n","epoch: 104loss: tensor(0.9393)\n","epoch: 105loss: tensor(0.9375)\n","epoch: 106loss: tensor(0.9403)\n","epoch: 107loss: tensor(0.9383)\n","epoch: 108loss: tensor(0.9397)\n","epoch: 109loss: tensor(0.9380)\n","epoch: 110loss: tensor(0.9391)\n","epoch: 111loss: tensor(0.9358)\n","epoch: 112loss: tensor(0.9375)\n","epoch: 113loss: tensor(0.9357)\n","epoch: 114loss: tensor(0.9365)\n","epoch: 115loss: tensor(0.9342)\n","epoch: 116loss: tensor(0.9349)\n","epoch: 117loss: tensor(0.9342)\n","epoch: 118loss: tensor(0.9355)\n","epoch: 119loss: tensor(0.9340)\n","epoch: 120loss: tensor(0.9349)\n","epoch: 121loss: tensor(0.9330)\n","epoch: 122loss: tensor(0.9340)\n","epoch: 123loss: tensor(0.9322)\n","epoch: 124loss: tensor(0.9329)\n","epoch: 125loss: tensor(0.9320)\n","epoch: 126loss: tensor(0.9328)\n","epoch: 127loss: tensor(0.9310)\n","epoch: 128loss: tensor(0.9312)\n","epoch: 129loss: tensor(0.9303)\n","epoch: 130loss: tensor(0.9307)\n","epoch: 131loss: tensor(0.9301)\n","epoch: 132loss: tensor(0.9298)\n","epoch: 133loss: tensor(0.9299)\n","epoch: 134loss: tensor(0.9294)\n","epoch: 135loss: tensor(0.9284)\n","epoch: 136loss: tensor(0.9290)\n","epoch: 137loss: tensor(0.9283)\n","epoch: 138loss: tensor(0.9281)\n","epoch: 139loss: tensor(0.9272)\n","epoch: 140loss: tensor(0.9276)\n","epoch: 141loss: tensor(0.9267)\n","epoch: 142loss: tensor(0.9273)\n","epoch: 143loss: tensor(0.9268)\n","epoch: 144loss: tensor(0.9273)\n","epoch: 145loss: tensor(0.9249)\n","epoch: 146loss: tensor(0.9264)\n","epoch: 147loss: tensor(0.9248)\n","epoch: 148loss: tensor(0.9255)\n","epoch: 149loss: tensor(0.9244)\n","epoch: 150loss: tensor(0.9247)\n","epoch: 151loss: tensor(0.9237)\n","epoch: 152loss: tensor(0.9242)\n","epoch: 153loss: tensor(0.9237)\n","epoch: 154loss: tensor(0.9238)\n","epoch: 155loss: tensor(0.9232)\n","epoch: 156loss: tensor(0.9238)\n","epoch: 157loss: tensor(0.9227)\n","epoch: 158loss: tensor(0.9226)\n","epoch: 159loss: tensor(0.9225)\n","epoch: 160loss: tensor(0.9223)\n","epoch: 161loss: tensor(0.9217)\n","epoch: 162loss: tensor(0.9231)\n","epoch: 163loss: tensor(0.9232)\n","epoch: 164loss: tensor(0.9223)\n","epoch: 165loss: tensor(0.9218)\n","epoch: 166loss: tensor(0.9216)\n","epoch: 167loss: tensor(0.9211)\n","epoch: 168loss: tensor(0.9212)\n","epoch: 169loss: tensor(0.9207)\n","epoch: 170loss: tensor(0.9202)\n","epoch: 171loss: tensor(0.9199)\n","epoch: 172loss: tensor(0.9203)\n","epoch: 173loss: tensor(0.9196)\n","epoch: 174loss: tensor(0.9203)\n","epoch: 175loss: tensor(0.9196)\n","epoch: 176loss: tensor(0.9202)\n","epoch: 177loss: tensor(0.9188)\n","epoch: 178loss: tensor(0.9191)\n","epoch: 179loss: tensor(0.9187)\n","epoch: 180loss: tensor(0.9196)\n","epoch: 181loss: tensor(0.9179)\n","epoch: 182loss: tensor(0.9193)\n","epoch: 183loss: tensor(0.9189)\n","epoch: 184loss: tensor(0.9186)\n","epoch: 185loss: tensor(0.9178)\n","epoch: 186loss: tensor(0.9185)\n","epoch: 187loss: tensor(0.9173)\n","epoch: 188loss: tensor(0.9177)\n","epoch: 189loss: tensor(0.9174)\n","epoch: 190loss: tensor(0.9178)\n","epoch: 191loss: tensor(0.9176)\n","epoch: 192loss: tensor(0.9177)\n","epoch: 193loss: tensor(0.9170)\n","epoch: 194loss: tensor(0.9172)\n","epoch: 195loss: tensor(0.9170)\n","epoch: 196loss: tensor(0.9168)\n","epoch: 197loss: tensor(0.9163)\n","epoch: 198loss: tensor(0.9167)\n","epoch: 199loss: tensor(0.9160)\n","epoch: 200loss: tensor(0.9164)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Bak5uc8gd-gX"},"source":["## Testing the SAE\n"]},{"cell_type":"code","metadata":{"id":"5ztvzYRtiGCz","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"d0e8ea8b-9ac4-40e5-a19a-7fcfc6934d61"},"source":["test_loss = 0\n","s = 0.\n","for id_user in range(nb_users):\n","  input = Variable(training_set[id_user]).unsqueeze(0)\n","  target = Variable(test_set[id_user]).unsqueeze(0)\n","  if torch.sum(target.data > 0) > 0:\n","    output = sae(input)\n","    target.require_grad = False\n","    output[target == 0] = 0\n","    loss = criterion(output, target)\n","    mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n","    test_loss += np.sqrt(loss.data*mean_corrector)\n","    s += 1.\n","print('test loss: '+str(test_loss/s))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["test loss: tensor(0.9681)\n"],"name":"stdout"}]}]}