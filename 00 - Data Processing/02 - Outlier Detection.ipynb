{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"colab":{"provenance":[]}},"cells":[{"cell_type":"markdown","source":["# 1. Data Processing"],"metadata":{"id":"n-_NUcV2XXTf"}},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-07-31T03:49:45.774456Z","start_time":"2020-07-31T03:49:45.768212Z"},"id":"qe7_1EOYPaQP"},"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import IsolationForest\n","from sklearn.covariance import EllipticEnvelope\n","from sklearn.neighbors import LocalOutlierFactor\n","from sklearn.svm import OneClassSVM"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-07-31T03:44:19.960927Z","start_time":"2020-07-31T03:44:19.876245Z"},"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"zVD3YUZnPaQa","executionInfo":{"status":"ok","timestamp":1632938766464,"user_tz":-480,"elapsed":15,"user":{"displayName":"Chan Chee Kean","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05792587367281359063"}},"outputId":"d75f7fc4-e6f6-4c67-ce2e-27aee054d96c"},"source":["# load the dataset\n","url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/housing.csv'\n","df = pd.read_csv(url, header=None)\n","df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.00632</td>\n","      <td>18.0</td>\n","      <td>2.31</td>\n","      <td>0</td>\n","      <td>0.538</td>\n","      <td>6.575</td>\n","      <td>65.2</td>\n","      <td>4.0900</td>\n","      <td>1</td>\n","      <td>296.0</td>\n","      <td>15.3</td>\n","      <td>396.90</td>\n","      <td>4.98</td>\n","      <td>24.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.02731</td>\n","      <td>0.0</td>\n","      <td>7.07</td>\n","      <td>0</td>\n","      <td>0.469</td>\n","      <td>6.421</td>\n","      <td>78.9</td>\n","      <td>4.9671</td>\n","      <td>2</td>\n","      <td>242.0</td>\n","      <td>17.8</td>\n","      <td>396.90</td>\n","      <td>9.14</td>\n","      <td>21.6</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.02729</td>\n","      <td>0.0</td>\n","      <td>7.07</td>\n","      <td>0</td>\n","      <td>0.469</td>\n","      <td>7.185</td>\n","      <td>61.1</td>\n","      <td>4.9671</td>\n","      <td>2</td>\n","      <td>242.0</td>\n","      <td>17.8</td>\n","      <td>392.83</td>\n","      <td>4.03</td>\n","      <td>34.7</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.03237</td>\n","      <td>0.0</td>\n","      <td>2.18</td>\n","      <td>0</td>\n","      <td>0.458</td>\n","      <td>6.998</td>\n","      <td>45.8</td>\n","      <td>6.0622</td>\n","      <td>3</td>\n","      <td>222.0</td>\n","      <td>18.7</td>\n","      <td>394.63</td>\n","      <td>2.94</td>\n","      <td>33.4</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.06905</td>\n","      <td>0.0</td>\n","      <td>2.18</td>\n","      <td>0</td>\n","      <td>0.458</td>\n","      <td>7.147</td>\n","      <td>54.2</td>\n","      <td>6.0622</td>\n","      <td>3</td>\n","      <td>222.0</td>\n","      <td>18.7</td>\n","      <td>396.90</td>\n","      <td>5.33</td>\n","      <td>36.2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        0     1     2   3      4      5   ...  8      9     10      11    12    13\n","0  0.00632  18.0  2.31   0  0.538  6.575  ...   1  296.0  15.3  396.90  4.98  24.0\n","1  0.02731   0.0  7.07   0  0.469  6.421  ...   2  242.0  17.8  396.90  9.14  21.6\n","2  0.02729   0.0  7.07   0  0.469  7.185  ...   2  242.0  17.8  392.83  4.03  34.7\n","3  0.03237   0.0  2.18   0  0.458  6.998  ...   3  222.0  18.7  394.63  2.94  33.4\n","4  0.06905   0.0  2.18   0  0.458  7.147  ...   3  222.0  18.7  396.90  5.33  36.2\n","\n","[5 rows x 14 columns]"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-07-31T03:44:20.327494Z","start_time":"2020-07-31T03:44:20.317903Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"tTwuP9icPaQc","executionInfo":{"status":"ok","timestamp":1632938766467,"user_tz":-480,"elapsed":15,"user":{"displayName":"Chan Chee Kean","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05792587367281359063"}},"outputId":"48f95f24-5c3e-4823-cd6d-ca23a610a5c9"},"source":["data = df.values\n","X, y = data[:, :-1], data[:, -1]\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n","print(X_train.shape, y_train.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(339, 13) (339,)\n"]}]},{"cell_type":"markdown","source":["# 2. Novelty and Outlier Detection\n","\n","[SkLearn Overview of outlier detection methods](https://scikit-learn.org/stable/modules/outlier_detection.html) | [SkLearn Anomaly Detection Algorithm](https://scikit-learn.org/stable/auto_examples/miscellaneous/plot_anomaly_comparison.html)"],"metadata":{"id":"001MktP3Xd0y"}},{"cell_type":"markdown","metadata":{"id":"RqxK78OpPaQZ"},"source":["## 2.1 Isolation Forest\n","\n","Anomalies, due to their nature, they have the shortest path in the trees than normal instances.\n","\n","[Isolation Forest Explained](https://towardsdatascience.com/isolation-forest-the-anomaly-detection-algorithm-any-data-scientist-should-know-1a99622eec2d)\n","| [Isolation Forest from Scratch](https://towardsdatascience.com/isolation-forest-from-scratch-e7e5978e6f4c)\n"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-07-31T03:45:44.349983Z","start_time":"2020-07-31T03:45:44.080903Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"Z5DlqLZDPaQd","executionInfo":{"status":"ok","timestamp":1632841430796,"user_tz":-480,"elapsed":274,"user":{"displayName":"Chan Chee Kean","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05792587367281359063"}},"outputId":"a20e972f-42a3-4c81-ec9f-2c1416471a8c"},"source":["ifo = IsolationForest(n_estimators=100, contamination=0.1)\n","mask = ifo.fit_predict(X_train)\n","# 34 outlier\n","X_train[(mask != 1), :].shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(34, 13)"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"W5vTLqNePaQe"},"source":["## 2.2 Minimum Covariance Determinant\n","\n","If the input variables have a Gaussian distribution, then simple statistical methods can be used to detect outliers."]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-07-31T03:47:58.976154Z","start_time":"2020-07-31T03:47:58.894765Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"07wjkAOAPaQf","executionInfo":{"status":"ok","timestamp":1632939362222,"user_tz":-480,"elapsed":567,"user":{"displayName":"Chan Chee Kean","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05792587367281359063"}},"outputId":"43f1e3ee-58d2-47a1-a7dd-d294f9d8260c"},"source":["ee = EllipticEnvelope(contamination=0.1)\n","ee_mask = ee.fit_predict(X_train)\n","# 34 outlier\n","X_train[(ee_mask != 1), :].shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(34, 13)"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JCEk1_XAxRUb","executionInfo":{"status":"ok","timestamp":1632939388077,"user_tz":-480,"elapsed":388,"user":{"displayName":"Chan Chee Kean","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05792587367281359063"}},"outputId":"75094e53-a27c-49d1-f70a-57e094153082"},"source":["ee.covariance_.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(13, 13)"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oMFj86h1xi6J","executionInfo":{"status":"ok","timestamp":1632939434385,"user_tz":-480,"elapsed":613,"user":{"displayName":"Chan Chee Kean","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05792587367281359063"}},"outputId":"76937e88-d7d1-410d-84d4-0656c8cf5b8a"},"source":["ee.location_"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1.80820711e+00, 8.51605505e+00, 9.05880734e+00, 4.12844037e-02,\n","       5.21805046e-01, 6.29650000e+00, 6.32330275e+01, 4.14108807e+00,\n","       8.54587156e+00, 3.73894495e+02, 1.84642202e+01, 3.87783165e+02,\n","       1.14200459e+01])"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"MOCj0QQGPaQf"},"source":["## 2.3 Local Outlier Factor\n","The anomaly score of each sample is called the Local Outlier Factor. It measures the local deviation of the density of a given sample with respect to its neighbors. It is local in that the anomaly score depends on how isolated the object is with respect to the surrounding neighborhood. More precisely, locality is given by k-nearest neighbors, whose distance is used to estimate the local density. By comparing the local density of a sample to the local densities of its neighbors, one can identify samples that have a substantially lower density than their neighbors. These are considered outliers.\n","\n","Brute Force may be the most accurate method due to the consideration of all data points. Hence, no data point is assigned to a false cluster. For small data sets, Brute Force is justifiable, however, for increasing data the KD or Ball Tree is better alternatives due to their speed and efficiency. The KD-tree and its variants can be termed “projective trees,” meaning that they categorize points based on their projection into some lower-dimensional space. (Kumar, Zhang & Nayar, 2008) or low-dimensional data, the KD Tree Algorithm might be the best solution. As seen above, the node divisions of the KD Tree are axis-aligned and cannot take a different shape. So the distribution might not be correctly mapped, leading to poor performance. For a high-dimensional space, the Ball Tree Algorithm might be the best solution. Its performance depends on the amount of training data, the dimensionality, and the structure of the data. Having many data points that are noise can also lead to a bad performance due to no clear structure.\n","\n","Note: Measures distances of n nearest neighbours. Only works well for feature spaces with low dimensionality.\n","\n","[Medium Ball Tree vs. KD Tree vs. Brute Force](https://towardsdatascience.com/tree-algorithms-explained-ball-tree-algorithm-vs-kd-tree-vs-brute-force-9746debcd940) | [Nearest Neighbors](https://scikit-learn.org/stable/modules/neighbors.html)\n"," | [SkLearn LocalOutlierFactor](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.LocalOutlierFactor.html#sklearn.neighbors.LocalOutlierFactor)\n","\n"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-07-31T03:48:08.138685Z","start_time":"2020-07-31T03:48:08.042516Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"V_hZJ5nHPaQh","executionInfo":{"status":"ok","timestamp":1632905428122,"user_tz":-480,"elapsed":299,"user":{"displayName":"Chan Chee Kean","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05792587367281359063"}},"outputId":"140a859c-73a8-476a-83ef-4cee7a30bcd8"},"source":["lof = LocalOutlierFactor()\n","lof_mask = lof.fit_predict(X_train)\n","X_train[(lof_mask != 1), :].shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(34, 13)"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X6OgdHNaw2lC","executionInfo":{"status":"ok","timestamp":1632905869663,"user_tz":-480,"elapsed":6,"user":{"displayName":"Chan Chee Kean","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05792587367281359063"}},"outputId":"44c8b75b-ae89-491b-b921-c7756ac86483"},"source":["# find nearest neightbour\n","print('Distance to neighbours', lof.kneighbors()[0][0])\n","print('Nearest Neighbours', lof.kneighbors()[1][0])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Distance to neighbours [ 4.23092261  5.10651982  7.05271079  7.84372942  8.70051763 10.69672104\n"," 10.80775442 11.186697   14.49075635 14.97747497 15.58867539 15.81042453\n"," 16.15736732 16.70677642 17.22434599 17.23959374 17.63102864 18.14385094\n"," 18.23231502 18.29698129]\n","Nearest Neighbours [ 87 113 123  60 255 168 284  26 170 176 329 128  17 311 169 315 333 323\n"," 163 336]\n"]}]},{"cell_type":"markdown","metadata":{"id":"anoL0-8pPaQh"},"source":["## 2.4 One-Class SVM\n","\n","Only one class for categorization, the boundary is set against the origin\n","\n","The OneClassSVM is known to be sensitive to outliers and thus does not perform very well for outlier detection. This estimator is best suited for novelty detection when the training set is not contaminated by outliers. That said, outlier detection in high-dimension, or without any assumptions on the distribution of the inlying data is very challenging, and a One-class SVM might give useful results in these situations depending on the value of its hyperparameters.\n","\n","SGDOneClassSVN has a linear complexity in the number of training samples and is thus better suited than the sklearn.svm.OneClassSVM implementation for datasets with a large number of training samples (say > 10,000).\n","\n","[One Class SVM for Anomaly Detection](https://machinelearninginterview.com/topics/machine-learning/what-is-one-class-svm-how-to-use-it-for-anomaly-detection/)"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-07-31T03:50:44.157989Z","start_time":"2020-07-31T03:50:44.068572Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"J6vR7HRuPaQi","executionInfo":{"status":"ok","timestamp":1632841059995,"user_tz":-480,"elapsed":11,"user":{"displayName":"Chan Chee Kean","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05792587367281359063"}},"outputId":"1e3a6033-3536-4534-a262-b809de4b2f63"},"source":["ocs = OneClassSVM(nu=0.01)\n","ee_mask = ee.fit_predict(X_train)\n","X_train[(ee_mask != 1), :].shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(34, 13)"]},"metadata":{},"execution_count":7}]}]}